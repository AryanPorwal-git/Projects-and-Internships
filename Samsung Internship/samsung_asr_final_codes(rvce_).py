# -*- coding: utf-8 -*-
"""Samsung ASR-Final Codes(RVCE )

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oHn6-hwMBvqcs6-w3cTO8tBz5CkVT9z4

Segmentation
"""

import re

def segment_text(text):
    sentences = re.split(r'(?<=[.!?]) +', text)
    return sentences

text = "Climate change: Bangladesh is where it is at. Rohini Kamal shows the way. Debates on climate change are often dominated by heated commentary from the West on its impending peril calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.  In our reality, it is a slow compounding of already familiar struggles.The worst impacts from climate change, in the form of heat stress, increased salinity, and erratic rainfall, play out within familiar struggles. They include calls for fair wages and working conditions. Improvements needed in the working environment  include a heightened need for water breaks and cooling – especially for those working outside or in enclosed cooking areas. These needs have now intensified in a hotter climate. Elsewhere in the workforce, heat stress, salinity, and rainfall compound farmers’ struggles against falling agricultural returns and land impacts from construction and development initiatives. The familiarity of these ongoing struggles exacerbates the risk of a continuance in our usual inadequate response to demands for better working and living conditions. So Bangladesh is facing climate change impacts full on. Not only are there physical changes, but socioeconomic fault lines are also being opened up. Economically marginalised communities continue to suffer from strains including unstable agricultural income, volatile pricing of their produce or the option of taking up urban job prospects.Rising sea levels have left their agricultural grounds with high salinity making them less fertile. Moreover, hasty and unplanned urbanisation has left areas with inadequate drainage systems and further saltwater intrusion from export-based aquaculture have made their problems worse. So they are often pressured to sell land for less than market value and are routinely threatened with fake cases that take years and large sums of money to resolve."
segments = segment_text(text)
for segment in segments:
    print(segment)

"""Feature Extraction"""

import spacy
from nltk.tokenize import word_tokenize

nlp = spacy.load("en_core_web_sm")

def extract_features(text):
    doc = nlp(text)
    features = []
    for token in doc:
        features.append({
            "word": token.text,
            "length": len(token.text),
            "pos": token.pos_
        })
    return features

text = "Climate change: Bangladesh is where it is at. Rohini Kamal shows the way. Debates on climate change are often dominated by heated commentary from the West on its impending peril calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.  In our reality, it is a slow compounding of already familiar struggles.The worst impacts from climate change, in the form of heat stress, increased salinity, and erratic rainfall, play out within familiar struggles. They include calls for fair wages and working conditions. Improvements needed in the working environment  include a heightened need for water breaks and cooling – especially for those working outside or in enclosed cooking areas. These needs have now intensified in a hotter climate. Elsewhere in the workforce, heat stress, salinity, and rainfall compound farmers’ struggles against falling agricultural returns and land impacts from construction and development initiatives. The familiarity of these ongoing struggles exacerbates the risk of a continuance in our usual inadequate response to demands for better working and living conditions. So Bangladesh is facing climate change impacts full on. Not only are there physical changes, but socioeconomic fault lines are also being opened up. Economically marginalised communities continue to suffer from strains including unstable agricultural income, volatile pricing of their produce or the option of taking up urban job prospects.Rising sea levels have left their agricultural grounds with high salinity making them less fertile. Moreover, hasty and unplanned urbanisation has left areas with inadequate drainage systems and further saltwater intrusion from export-based aquaculture have made their problems worse. So they are often pressured to sell land for less than market value and are routinely threatened with fake cases that take years and large sums of money to resolve."
features = extract_features(text)
for feature in features:
    print(feature)

"""Statistical analysis"""

import pandas as pd
from scipy import stats
from scipy.stats import chi2_contingency

read_speech_features = [
    {"word": "Climate", "length": 7, "pos": "NOUN"},
    {"word": "change", "length": 6, "pos": "NOUN"},
    {"word": "Bangladesh", "length": 10, "pos": "NOUN"},
    {"word": "is", "length": 2, "pos": "AUX"},
    {"word": "where", "length": 5, "pos": "ADV"},
    {"word": "it", "length": 2, "pos": "PRON"},
    {"word": "is", "length": 2, "pos": "AUX"},
    {"word": "at", "length": 2, "pos": "ADV"},
    # Add more read speech feature data here...
]

conv_speech_features = [
    {"word": "Climate", "length": 7, "pos": "NOUN"},
    {"word": "change", "length": 6, "pos": "NOUN"},
    {"word": "Bangladesh", "length": 11, "pos": "NOUN"},  # Different length in conversational speech
    {"word": "is", "length": 2, "pos": "AUX"},
    {"word": "where", "length": 5, "pos": "ADV"},
    {"word": "it", "length": 2, "pos": "PRON"},
    {"word": "is", "length": 2, "pos": "AUX"},
    {"word": "at", "length": 2, "pos": "ADV"},
    # Add more conversational speech feature data here...
]

# Convert lists of dictionaries to DataFrames
df_read = pd.DataFrame(read_speech_features)
df_conv = pd.DataFrame(conv_speech_features)

# Perform a paired t-test on the 'length' feature
t_stat, p_value = stats.ttest_rel(df_read['length'], df_conv['length'])
print(f"Paired T-statistic: {t_stat}, P-value: {p_value}")

# Count the occurrences of each POS tag
pos_counts_read = df_read['pos'].value_counts()
pos_counts_conv = df_conv['pos'].value_counts()

# Combine into a DataFrame for comparison
pos_comparison = pd.DataFrame({
    "read_speech": pos_counts_read,
    "conv_speech": pos_counts_conv
}).fillna(0)

print(pos_comparison)

# Perform chi-square test
chi2, p, dof, expected = chi2_contingency(pos_comparison)
print(f"Chi-square statistic: {chi2}, P-value: {p}")

"""Comparision of read speech and conversational speech"""

import pandas as pd
import nltk
from scipy import stats
from scipy.stats import chi2_contingency

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

# Example feature data for read and conversational speech for the same text
read_speech_features = [
    {"word": "Climate", "length": 7, "pos": "NOUN", "text": "Climate change: Bangladesh is where it is at."},
    {"word": "Rohini", "length": 6, "pos": "NOUN", "text": "Rohini Kamal shows the way."},
    # Add more read speech feature data here...
]

conv_speech_features = [
    {"word": "Climate", "length": 7, "pos": "NOUN", "text": "Climate change: Bangladesh is where it is at."},
    {"word": "Rohini", "length": 6, "pos": "NOUN", "text": "Rohini Kamal shows the way."},
    # Add more conversational speech feature data here...
]

# Convert lists of dictionaries to DataFrames
df_read = pd.DataFrame(read_speech_features)
df_conv = pd.DataFrame(conv_speech_features)

# Define filler words and contractions
filler_words = ["um", "uh", "like", "you know", "I mean", "so", "actually", "basically", "literally", "well"]
contractions = ["n't", "'re", "'s", "'d", "'ll", "'t", "'ve", "'m"]

# Helper function to count filler words
def count_filler_words(text, filler_words):
    return sum(word in text.split() for word in filler_words)

# Helper function to count contractions
def count_contractions(text, contractions):
    return sum(contraction in text for contraction in contractions)

# Helper function to analyze sentence structure
def analyze_sentence_structure(text):
    sentences = nltk.sent_tokenize(text)
    tagged_sentences = [nltk.pos_tag(nltk.word_tokenize(sentence)) for sentence in sentences]
    return tagged_sentences

# Add analysis columns to DataFrames
df_read['filler_count'] = df_read['text'].apply(lambda x: count_filler_words(x, filler_words))
df_conv['filler_count'] = df_conv['text'].apply(lambda x: count_filler_words(x, filler_words))

df_read['contraction_count'] = df_read['text'].apply(lambda x: count_contractions(x, contractions))
df_conv['contraction_count'] = df_conv['text'].apply(lambda x: count_contractions(x, contractions))

df_read['sentence_structure'] = df_read['text'].apply(analyze_sentence_structure)
df_conv['sentence_structure'] = df_conv['text'].apply(analyze_sentence_structure)

# Perform a paired t-test on the 'length' feature
t_stat, p_value = stats.ttest_rel(df_read['length'], df_conv['length'])
print(f"Paired T-statistic: {t_stat}, P-value: {p_value}")

# Count the occurrences of each POS tag
pos_counts_read = df_read['pos'].value_counts()
pos_counts_conv = df_conv['pos'].value_counts()

# Combine into a DataFrame for comparison
pos_comparison = pd.DataFrame({
    "read_speech": pos_counts_read,
    "conv_speech": pos_counts_conv
}).fillna(0)  # Fill NaN values with 0

print(pos_comparison)

# Perform chi-square test
chi2, p, dof, expected = chi2_contingency(pos_comparison)
print(f"Chi-square statistic: {chi2}, P-value: {p}")

# Summary statistics for filler words
filler_stats_read = df_read['filler_count'].describe()
filler_stats_conv = df_conv['filler_count'].describe()

print("Filler words in read speech:\n", filler_stats_read)
print("Filler words in conversational speech:\n", filler_stats_conv)

# Summary statistics for contractions
contraction_stats_read = df_read['contraction_count'].describe()
contraction_stats_conv = df_conv['contraction_count'].describe()

print("Contractions in read speech:\n", contraction_stats_read)
print("Contractions in conversational speech:\n", contraction_stats_conv)

# Sample sentence structures for comparison
print("Sentence structure in read speech:\n", df_read['sentence_structure'].head())
print("Sentence structure in conversational speech:\n", df_conv['sentence_structure'].head())

"""Data Augmentation"""

!pip install transformers torch

"""T5 MODEL TO GENERATE PARAPHRASES"""

import pandas as pd
from transformers import T5ForConditionalGeneration, T5Tokenizer
import torch

# Load the T5 model and tokenizer
model_name = "t5-base"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)

def generate_paraphrases(text, num_paraphrases=3):
    # Prepare the input text for T5
    input_text = f"paraphrase: {text} </s>"
    encoding = tokenizer.encode_plus(input_text, padding=True, return_tensors="pt")
    input_ids, attention_mask = encoding["input_ids"], encoding["attention_mask"]

    # Generate paraphrases
    outputs = model.generate(
        input_ids=input_ids,
        attention_mask=attention_mask,
        max_length=256,
        num_beams=10,
        num_return_sequences=num_paraphrases,
        temperature=1.5,
    )

    # Decode the generated texts
    paraphrases = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]
    return paraphrases

# Example pairs of read and conversational speech
data = [
    {"read": "Climate change: Bangladesh is where it is at.", "conv": "Climate change is really hitting Bangladesh hard."},
    {"read": "Rohini Kamal shows the way.", "conv": "Rohini Kamal is leading the way."},
    # Add more pairs...
]

# Convert to DataFrame
df = pd.DataFrame(data)

# Generate paraphrases for read and conversational speech
df['read_paraphrases'] = df['read'].apply(lambda x: generate_paraphrases(x))
df['conv_paraphrases'] = df['conv'].apply(lambda x: generate_paraphrases(x))

# Flatten the DataFrame for easier handling
df_expanded = df.explode('read_paraphrases').explode('conv_paraphrases')

print(df_expanded)

"""LSTM Model"""

!pip install tensorflow

"""Preprocess a given text and prepare it for training a text generation model using n-gram sequences."""

import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Define your text
text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
In our reality, it is a slow compounding of already familiar struggles. The worst impacts from climate change,
in the form of heat stress, increased salinity, and erratic rainfall, play out within familiar struggles.
They include calls for fair wages and working conditions. Improvements needed in the working environment include
a heightened need for water breaks and cooling – especially for those working outside or in enclosed cooking areas.
These needs have now intensified in a hotter climate. Elsewhere in the workforce, heat stress, salinity, and rainfall compound farmers’
struggles against falling agricultural returns and land impacts from construction and development initiatives.
The familiarity of these ongoing struggles exacerbates the risk of a continuance in our usual inadequate response to demands
for better working and living conditions. So Bangladesh is facing climate change impacts full on. Not only are there physical changes,
but socioeconomic fault lines are also being opened up. Economically marginalised communities continue to suffer from strains
including unstable agricultural income, volatile pricing of their produce or the option of taking up urban job prospects.
Rising sea levels have left their agricultural grounds with high salinity making them less fertile. Moreover, hasty and unplanned urbanisation
has left areas with inadequate drainage systems and further saltwater intrusion from export-based aquaculture have made their problems worse.
So they are often pressured to sell land for less than market value and are routinely threatened with fake cases that take years and large sums of money to resolve.
"""

# Tokenize the text
tokenizer = Tokenizer()
tokenizer.fit_on_texts([text])
total_words = len(tokenizer.word_index) + 1

# Create input sequences
input_sequences = []
for line in text.split('\n'):
    token_list = tokenizer.texts_to_sequences([line])[0]
    for i in range(1, len(token_list)):
        n_gram_sequence = token_list[:i+1]
        input_sequences.append(n_gram_sequence)

# Pad sequences
max_sequence_len = max([len(x) for x in input_sequences])
input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))

# Create predictors and label
X = input_sequences[:, :-1]
y = input_sequences[:, -1]

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

embedding_dim = 256

model = Sequential()
model.add(Embedding(total_words, embedding_dim, input_length=max_sequence_len-1))
model.add(LSTM(embedding_dim))
model.add(Dense(total_words, activation='softmax'))

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
print(model.summary())

model.fit(X, y, epochs=50, verbose=1)

"""Pretrained model:VADER

"""

!pip install nltk

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download VADER Lexicon (if not already downloaded)
nltk.download('vader_lexicon')

# Initialize VADER
sid = SentimentIntensityAnalyzer()

def detect_emotion(text):
    # Perform sentiment analysis using VADER
    scores = sid.polarity_scores(text)
    # Determine emotion based on compound score
    if scores['compound'] >= 0.05:
        emotion = 'Positive'
    elif scores['compound'] <= -0.05:
        emotion = 'Negative'
    else:
        emotion = 'Neutral'
    return emotion

# Example usage
text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""
emotion = detect_emotion(text)
print(f"Detected emotion: {emotion}")

!pip install vaderSentiment

"""Analyzing the emotional tone of the transformed text using the VADER(Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool."""

# Importing necessary modules after installation
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Function to transform read speech into conversational speech
def transform_to_conversational(text):
    # Simplify and transform the text to conversational style (simplified for illustration)
    transformed_text = text.lower()  # Convert to lowercase for simplicity
    transformed_text = transformed_text.replace("climate change", "climate issues")
    transformed_text = transformed_text.replace("debates", "discussions")

    return transformed_text

# Function to detect emotion using VADER
def detect_emotion(text):
    analyzer = SentimentIntensityAnalyzer()
    sentiment_scores = analyzer.polarity_scores(text)

    # Determine emotional tone based on compound score
    if sentiment_scores['compound'] >= 0.05:
        emotion = "Positive"
    elif sentiment_scores['compound'] <= -0.05:
        emotion = "Negative"
    else:
        emotion = "Neutral"

    return emotion

# Example text
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Transform the text to conversational style
transformed_text = transform_to_conversational(original_text)

# Detect emotion in the transformed text
detected_emotion = detect_emotion(transformed_text)

# Print results
print("Original Text:")
print(original_text)
print("\nTransformed Conversational Text:")
print(transformed_text)
print("\nDetected Emotion:")
print(detected_emotion)

"""Transformation of read speech to conversational speech

Libraries and Tools Used
1. SpeechRecognition:
   - **Model**: Google's Speech Recognition API
   - **Purpose**: Convert audio files to text.
   - **Installation**: `pip install SpeechRecognition`

2. gTTS (Google Text-to-Speech):
   - **Model**: Google Text-to-Speech
   - **Purpose**: Convert text to audio.
   - **Installation**: `pip install gTTS`

3. Regular Expressions (`re`):
   - **Purpose**: Segment text into sentences.

4. Google Colab's `files` module:
   - **Purpose**: Download files from the Colab environment.


Models Used
- Google's Speech Recognition API: A cloud-based speech-to-text model that converts spoken language into written text.
- Google Text-to-Speech (gTTS): A cloud-based text-to-speech model that converts written text into spoken audio.


"""

# Install necessary libraries
!pip install SpeechRecognition pyttsx3 gTTS

import speech_recognition as sr
import re
from gtts import gTTS
import os
from google.colab import files  # Importing Google Colab's files module

# Function to segment text into sentences
def segment_text(text):
    sentences = re.split(r'(?<=[.!?]) +', text)
    return sentences

# Function to transform read speech into conversational speech
def transform_to_conversational(text):
    # Simplify and transform the text to conversational style
    transformed_text = text.lower()  # Convert to lowercase for simplicity
    transformed_text = transformed_text.replace("climate change", "climate issues")
    transformed_text = transformed_text.replace("debates", "discussions")
    # Add more transformations as needed

    return transformed_text

# Function to convert audio file to text using SpeechRecognition
def audio_to_text(audio_file):
    recognizer = sr.Recognizer()

    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)

    try:
        text = recognizer.recognize_google(audio_data)
        return text
    except sr.UnknownValueError:
        print("Speech recognition could not understand audio")
    except sr.RequestError as e:
        print(f"Could not request results from Google Speech Recognition service; {e}")

    return None

# Function to convert text to audio using gTTS
def text_to_audio(text, output_file):
    tts = gTTS(text=text, lang='en')
    tts.save(output_file)

# Example text for transformation and speech conversion
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Segment the original text into sentences
segments = segment_text(original_text)

# Assuming the audio file is named 'read_speech.wav' and located in the current directory
audio_file = "/content/drive/MyDrive/Sample 1.wav"

# Step 1: Convert Audio to Text
read_speech_text = audio_to_text(audio_file)

if read_speech_text:
    print("Read Speech Transcription:")
    print(read_speech_text)
    print("\n")

    # Step 2: Transform Text to Conversational Style
    conversational_text = transform_to_conversational(read_speech_text)
    print("Transformed Conversational Text:")
    print(conversational_text)
    print("\n")

    # Step 3: Convert Text to Audio
    output_file = "/content/conversational_speech.wav"
    text_to_audio(conversational_text, output_file)
    print(f"Conversion complete. Conversational speech saved to {output_file}")

    # Download the conversational speech file
    files.download(output_file)
else:
    print("Speech recognition failed. Check the audio file or service availability.")

"""Displaying accuracy"""

# Install necessary libraries
!pip install SpeechRecognition pyttsx3 gTTS nltk

import speech_recognition as sr
import re
from gtts import gTTS
import os
from google.colab import files  # Importing Google Colab's files module
import nltk
from nltk.metrics import jaccard_distance
from nltk.tokenize import word_tokenize
import string

nltk.download('punkt')

# Function to segment text into sentences
def segment_text(text):
    sentences = re.split(r'(?<=[.!?]) +', text)
    return sentences

# Function to transform read speech into conversational speech
def transform_to_conversational(text):
    # Simplify and transform the text to conversational style
    transformed_text = text.lower()  # Convert to lowercase for simplicity
    transformed_text = transformed_text.replace("climate change", "climate issues")
    transformed_text = transformed_text.replace("debates", "discussions")
    # Add more transformations as needed

    return transformed_text

# Function to convert audio file to text using SpeechRecognition
def audio_to_text(audio_file):
    recognizer = sr.Recognizer()

    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)

    try:
        text = recognizer.recognize_google(audio_data)
        return text
    except sr.UnknownValueError:
        print("Speech recognition could not understand audio")
    except sr.RequestError as e:
        print(f"Could not request results from Google Speech Recognition service; {e}")

    return None

# Function to convert text to audio using gTTS
def text_to_audio(text, output_file):
    tts = gTTS(text=text, lang='en')
    tts.save(output_file)

# Function to calculate Jaccard similarity
def jaccard_similarity(text1, text2):
    # Tokenize text and remove punctuation
    tokens1 = set(word_tokenize(text1.lower()))
    tokens2 = set(word_tokenize(text2.lower()))

    # Calculate Jaccard similarity
    jaccard_sim = 1 - jaccard_distance(tokens1, tokens2)
    return jaccard_sim

# Example text for transformation and speech conversion
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Segment the original text into sentences
segments = segment_text(original_text)

# Assuming the audio file is named 'read_speech.wav' and located in the current directory
audio_file = "/content/drive/MyDrive/Sample 1.wav"

# Step 1: Convert Audio to Text
read_speech_text = audio_to_text(audio_file)

if read_speech_text:
    print("Read Speech Transcription:")
    print(read_speech_text)
    print("\n")

    # Step 2: Transform Text to Conversational Style
    conversational_text = transform_to_conversational(read_speech_text)
    print("Transformed Conversational Text:")
    print(conversational_text)
    print("\n")

    # Calculate accuracy using Jaccard similarity
    accuracy = jaccard_similarity(original_text, conversational_text)
    print(f"Conversion Accuracy (Jaccard Similarity): {accuracy:.2f}")

    # Step 3: Convert Text to Audio
    output_file = "/content/conversational_speech.wav"
    text_to_audio(conversational_text, output_file)
    print(f"Conversion complete. Conversational speech saved to {output_file}")

    # Download the conversational speech file
    files.download(output_file)
else:
    print("Speech recognition failed. Check the audio file or service availability.")

"""Improved Accuracy with t5-small Transformer model"""

# Install necessary libraries
!pip install SpeechRecognition pyttsx3 gTTS nltk transformers

import speech_recognition as sr
import re
from gtts import gTTS
import os
from google.colab import files
import nltk
from nltk.metrics import jaccard_distance
from nltk.tokenize import word_tokenize
from transformers import pipeline

nltk.download('punkt')

# Function to segment text into sentences
def segment_text(text):
    sentences = re.split(r'(?<=[.!?]) +', text)
    return sentences

# Function to transform read speech into conversational speech using a transformer model
def transform_to_conversational(text):
    # Load a pre-trained transformer model for text summarization or transformation
    transformer = pipeline('text2text-generation', model='t5-small')

    # Transform the text
    transformed_text = transformer(text, max_length=512, truncation=True)[0]['generated_text']

    return transformed_text

# Function to convert audio file to text using SpeechRecognition
def audio_to_text(audio_file):
    recognizer = sr.Recognizer()

    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)

    try:
        text = recognizer.recognize_google(audio_data)
        return text
    except sr.UnknownValueError:
        print("Speech recognition could not understand audio")
    except sr.RequestError as e:
        print(f"Could not request results from Google Speech Recognition service; {e}")

    return None

# Function to convert text to audio using gTTS
def text_to_audio(text, output_file):
    tts = gTTS(text=text, lang='en')
    tts.save(output_file)

# Function to calculate Jaccard similarity
def jaccard_similarity(text1, text2):
    # Tokenize text and remove punctuation
    tokens1 = set(word_tokenize(text1.lower()))
    tokens2 = set(word_tokenize(text2.lower()))

    # Calculate Jaccard similarity
    jaccard_sim = 1 - jaccard_distance(tokens1, tokens2)
    return jaccard_sim

# Example text for transformation and speech conversion
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Segment the original text into sentences
segments = segment_text(original_text)

# Assuming the audio file is named 'read_speech.wav' and located in the current directory
audio_file = "/content/drive/MyDrive/Sample 1.wav"

# Step 1: Convert Audio to Text
read_speech_text = audio_to_text(audio_file)

if read_speech_text:
    print("Read Speech Transcription:")
    print(read_speech_text)
    print("\n")

    # Step 2: Transform Text to Conversational Style
    conversational_text = transform_to_conversational(read_speech_text)
    print("Transformed Conversational Text:")
    print(conversational_text)
    print("\n")

    # Calculate accuracy using Jaccard similarity
    accuracy = jaccard_similarity(original_text, conversational_text)
    print(f"Conversion Accuracy (Jaccard Similarity): {accuracy:.2f}")

    # Step 3: Convert Text to Audio
    output_file = "/content/conversational_speech.wav"
    text_to_audio(conversational_text, output_file)
    print(f"Conversion complete. Conversational speech saved to {output_file}")

    # Download the conversational speech file
    files.download(output_file)
else:
    print("Speech recognition failed. Check the audio file or service availability.")

from google.colab import drive
drive.mount('/content/drive')

# Install necessary libraries
!pip install SpeechRecognition pyttsx3 gTTS nltk

import speech_recognition as sr
import re
from gtts import gTTS
import os
from google.colab import files  # Importing Google Colab's files module
import nltk
from nltk.metrics import jaccard_distance
from nltk.tokenize import word_tokenize
import string

nltk.download('punkt')

# Function to segment text into sentences
def segment_text(text):
    sentences = re.split(r'(?<=[.!?]) +', text)
    return sentences

# Function to transform read speech into conversational speech
def transform_to_conversational(text):
    # Simplify and transform the text to conversational style
    transformed_text = text.lower()  # Convert to lowercase for simplicity
    transformed_text = transformed_text.replace("climate change", "climate issues")
    transformed_text = transformed_text.replace("debates", "discussions")
    # Add more transformations as needed

    return transformed_text

# Function to convert audio file to text using SpeechRecognition
def audio_to_text(audio_file):
    recognizer = sr.Recognizer()

    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)

    try:
        text = recognizer.recognize_google(audio_data)
        return text
    except sr.UnknownValueError:
        print("Speech recognition could not understand audio")
    except sr.RequestError as e:
        print(f"Could not request results from Google Speech Recognition service; {e}")

    return None

# Function to convert text to audio using gTTS
def text_to_audio(text, output_file):
    tts = gTTS(text=text, lang='en')
    tts.save(output_file)

# Function to preprocess text (lowercase, remove punctuation)
def preprocess_text(text):
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    return text

# Function to calculate Jaccard similarity
def jaccard_similarity(text1, text2):
    # Preprocess texts
    text1 = preprocess_text(text1)
    text2 = preprocess_text(text2)

    # Tokenize text using nltk
    tokens1 = set(word_tokenize(text1))
    tokens2 = set(word_tokenize(text2))

    # Calculate Jaccard similarity
    if len(tokens1.union(tokens2)) == 0:
        return 0  # handle case where both sets are empty
    else:
        jaccard_sim = len(tokens1.intersection(tokens2)) / len(tokens1.union(tokens2))
        return jaccard_sim

# Function to calculate MOS score based on Jaccard similarity
def calculate_mos_score(jaccard_similarity):
    # Adjust the MOS scoring function based on your empirical data or user feedback
    if jaccard_similarity >= 0.9:
        mos_score = 5.0
    elif jaccard_similarity >= 0.7:
        mos_score = 4.0
    elif jaccard_similarity >= 0.5:
        mos_score = 3.0
    elif jaccard_similarity >= 0.3:
        mos_score = 2.0
    else:
        mos_score = 1.0

    return mos_score

# Example text for transformation and speech conversion
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Segment the original text into sentences
segments = segment_text(original_text)

# Assuming the audio file is named 'read_speech.wav' and located in the current directory
audio_file = "/content/drive/MyDrive/Sample 1.wav"

# Step 1: Convert Audio to Text
read_speech_text = audio_to_text(audio_file)

if read_speech_text:
    print("Read Speech Transcription:")
    print(read_speech_text)
    print("\n")

    # Step 2: Transform Text to Conversational Style
    conversational_text = transform_to_conversational(read_speech_text)
    print("Transformed Conversational Text:")
    print(conversational_text)
    print("\n")

    # Calculate accuracy using Jaccard similarity
    accuracy = jaccard_similarity(original_text, conversational_text)
    print(f"Conversion Accuracy (Jaccard Similarity): {accuracy:.2f}")

    # Step 3: Calculate MOS Score
    mos_score = calculate_mos_score(accuracy)
    print(f"Estimated MOS Score: {mos_score:.2f}")

    # Step 4: Convert Text to Audio
    output_file = "/content/conversational_speech.wav"
    text_to_audio(conversational_text, output_file)
    print(f"Conversion complete. Conversational speech saved to {output_file}")

    # Download the conversational speech file
    files.download(output_file)
else:
    print("Speech recognition failed. Check the audio file or service availability.")

!pip install SpeechRecognition pyttsx3 gTTS nltk

!pip install requests

!pip install TTS torchaudio==0.9.0 torch==1.8.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html
!pip install soundfile nltk

!wget https://github.com/coqui-ai/TTS/releases/download/v0.0.3/tts_models_tacotron2_ljspeech.pth.tar
!wget https://raw.githubusercontent.com/coqui-ai/TTS/master/tts/configs/config.json

!pip install TTS

from google.colab import files

# Upload the service account key JSON file
uploaded = files.upload()

import os

# List files in the /content directory
files_in_colab = os.listdir('/content')
print(files_in_colab)

import os

# Set Google Application Credentials environment variable
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "iron-handler-427712-v3-73377cf3491b.json"

print(f"Credentials set to: {os.environ['GOOGLE_APPLICATION_CREDENTIALS']}")

import os
from google.cloud import texttospeech

# Set up Google Cloud Text-to-Speech client
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "iron-handler-427712-v3-73377cf3491b.json"
client = texttospeech.TextToSpeechClient()

# Function to Convert Text to Speech with Emotional Tone
def text_to_speech(text, emotion="neutral"):
    # Define the voice selection parameters
    if emotion == "joyful":
        ssml_gender = texttospeech.SsmlVoiceGender.FEMALE  # Adjust gender for joyful tone
    elif emotion == "sad":
        ssml_gender = texttospeech.SsmlVoiceGender.MALE  # Adjust gender for sad tone
    else:
        ssml_gender = texttospeech.SsmlVoiceGender.NEUTRAL  # Default to neutral tone

    # Synthesize speech with specified emotional tone
    synthesis_input = texttospeech.SynthesisInput(text=text)
    voice_params = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        ssml_gender=ssml_gender
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )
    response = client.synthesize_speech(
        input=synthesis_input, voice=voice_params, audio_config=audio_config
    )
    return response.audio_content

# Sample text about climate issues
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Function to segment text into sentences
def segment_text(text):
    sentences = text.split('\n')
    return sentences

# Step 1: Segment the original text into sentences
segments = segment_text(original_text)

# Step 2: Define emotions and convert text to speech with different emotions
emotions = ["neutral", "joyful", "sad"]
for emotion in emotions:
    print(f"Emotion: {emotion}")
    print("=========================")
    for segment in segments:
        if segment.strip() != "":
            audio_content = text_to_speech(segment, emotion)
            # Save or play the audio content (Example: Save as MP3 file)
            with open(f"{emotion}_speech.mp3", "wb") as f:
                f.write(audio_content)
            print(f"Segment: {segment.strip()}")

    print("\n")

print("Speech synthesis completed!")

import os
from google.cloud import texttospeech
from IPython.display import Audio, display

# Set up Google Cloud Text-to-Speech client
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "iron-handler-427712-v3-73377cf3491b.json"
client = texttospeech.TextToSpeechClient()

# Function to Convert Text to Speech with Emotional Tone
def text_to_speech(text, emotion="neutral"):
    # Define the voice selection parameters
    if emotion == "joyful":
        pitch = 20.0
        speaking_rate = 1.1
    elif emotion == "sad":
        pitch = -20.0
        speaking_rate = 0.9
    elif emotion == "angry":
        pitch = 10.0
        speaking_rate = 1.2
    else:
        pitch = 0.0
        speaking_rate = 1.0

    # Adjust the pitch and speaking rate based on emotion
    voice_params = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Wavenet-F",
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        pitch=pitch,
        speaking_rate=speaking_rate
    )
    synthesis_input = texttospeech.SynthesisInput(text=text)

    # Synthesize speech with specified emotional tone
    response = client.synthesize_speech(
        input=synthesis_input, voice=voice_params, audio_config=audio_config
    )
    return response.audio_content

# Sample text about climate issues
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Function to segment text into sentences
def segment_text(text):
    sentences = text.split('\n')
    return sentences

# Step 1: Segment the original text into sentences
segments = segment_text(original_text)

# Step 2: Define emotions and convert text to speech with different emotions
emotions = ["neutral", "joyful", "sad", "angry"]  # Add more emotions as needed
output_dir = "/content/output/"  # Specify the directory to save MP3 files

# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Initialize a list to store file paths
file_paths = []

for emotion in emotions:
    print(f"Emotion: {emotion}")
    print("=========================")
    for segment in segments:
        if segment.strip() != "":
            audio_content = text_to_speech(segment, emotion)
            # Save the audio content to a file
            file_path = os.path.join(output_dir, f"{emotion}_speech.mp3")
            with open(file_path, "wb") as f:
                f.write(audio_content)
            file_paths.append(file_path)
            print(f"Segment: {segment.strip()}")

            # Display and play the audio in Colab
            display(Audio(audio_content))

print("Speech synthesis completed!")

# Provide download links for all generated MP3 files
for file_path in file_paths:
    filename = os.path.basename(file_path)
    download_link = f"<a href='{file_path}' target='_blank'>Download {filename}</a>"

import os
from google.cloud import texttospeech
from IPython.display import Audio, display, HTML

# Set up Google Cloud Text-to-Speech client
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "iron-handler-427712-v3-73377cf3491b.json"
client = texttospeech.TextToSpeechClient()

# Function to Convert Text to Speech with Emotional Tone
def text_to_speech(text, pitch=0.0, speaking_rate=1.0):
    voice_params = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Wavenet-F",
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        pitch=pitch,
        speaking_rate=speaking_rate
    )
    synthesis_input = texttospeech.SynthesisInput(text=text)

    # Synthesize speech with specified emotional tone
    response = client.synthesize_speech(
        input=synthesis_input, voice=voice_params, audio_config=audio_config
    )
    return response.audio_content

# Sample text about climate issues
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Function to segment text into sentences
def segment_text(text):
    sentences = text.split('\n')
    return sentences

# Step 1: Segment the original text into sentences
segments = segment_text(original_text)

# Step 2: Define emotions and convert text to speech with different emotions
emotions = {
    "neutral": (0.0, 1.0),    # Default pitch and speaking rate
    "joyful": (5.0, 1.1),     # Slightly higher pitch and faster speaking rate
    "sad": (-5.0, 0.9),       # Slightly lower pitch and slower speaking rate
    "angry": (10.0, 1.2)      # Higher pitch and faster speaking rate
}

output_dir = "/content/output/"  # Specify the directory to save MP3 files

# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Initialize a list to store file paths
file_paths = []

for emotion, (pitch, speaking_rate) in emotions.items():
    print(f"Emotion: {emotion.capitalize()}")
    print("=========================")
    for segment in segments:
        if segment.strip() != "":
            audio_content = text_to_speech(segment, pitch=pitch, speaking_rate=speaking_rate)
            # Save the audio content to a file
            file_path = os.path.join(output_dir, f"{emotion}_speech.mp3")
            with open(file_path, "wb") as f:
                f.write(audio_content)
            file_paths.append(file_path)
            print(f"Segment: {segment.strip()}")

            # Display and play the audio in Colab
            display(Audio(audio_content))

print("Speech synthesis completed!")

# Provide download links for all generated MP3 files
for file_path in file_paths:
    filename = os.path.basename(file_path)
    download_link = f"<a href='{file_path}' target='_blank'>Download {filename}</a>"

!pip install google-cloud-texttospeech

import os
from google.cloud import texttospeech
from IPython.display import Audio, display, HTML

# Set up Google Cloud Text-to-Speech client
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "iron-handler-427712-v3-73377cf3491b.json"
client = texttospeech.TextToSpeechClient()

# Function to Convert Text to Speech with Emotional Tone using SSML
def text_to_speech_ssml(ssml_text):
    voice_params = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Wavenet-F",
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )
    synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)

    # Synthesize speech with specified emotional tone
    response = client.synthesize_speech(
        input=synthesis_input, voice=voice_params, audio_config=audio_config
    )
    return response.audio_content

# Sample text about climate issues
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Function to segment text into sentences
def segment_text(text):
    sentences = text.split('\n')
    return sentences

# Step 1: Segment the original text into sentences
segments = segment_text(original_text)

# Step 2: Define emotions and convert text to speech with different emotions
emotions = {
    "neutral": "<prosody pitch='0%' rate='1.0'>",
    "joyful": "<prosody pitch='+10%' rate='1.1'>",
    "sad": "<prosody pitch='-10%' rate='0.9'>",
    "angry": "<prosody pitch='+20%' rate='1.2'>"
}

output_dir = "/content/output/"  # Specify the directory to save MP3 files

# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Initialize a list to store file paths
file_paths = []

for emotion, prosody in emotions.items():
    print(f"Emotion: {emotion.capitalize()}")
    print("=========================")
    ssml_parts = []
    for segment in segments:
        if segment.strip() != "":
            ssml_segment = f"<speak>{prosody}{segment.strip()}</prosody></speak>"
            audio_content = text_to_speech_ssml(ssml_segment)
            # Save the audio content to a file
            file_path = os.path.join(output_dir, f"{emotion}_speech.mp3")
            with open(file_path, "wb") as f:
                f.write(audio_content)
            file_paths.append(file_path)
            print(f"Segment: {segment.strip()}")

            # Display and play the audio in Colab
            display(Audio(audio_content))

print("Speech synthesis completed!")

# Provide download links for all generated MP3 files
for file_path in file_paths:
    filename = os.path.basename(file_path)
    download_link = f"<a href='{file_path}' target='_blank'>Download {filename}</a>"
    display(HTML(download_link))

"""To generate more human-like emotional speech, we can use SSML (Speech Synthesis Markup Language) to fine-tune the prosody parameters such as pitch, rate, and pauses"""

import os
from google.cloud import texttospeech
from IPython.display import Audio, display, HTML
import difflib

# Set up Google Cloud Text-to-Speech client
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "iron-handler-427712-v3-73377cf3491b.json"
client = texttospeech.TextToSpeechClient()

# Function to Convert Text to Speech with Emotional Tone using SSML
def text_to_speech_ssml(ssml_text):
    voice_params = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Wavenet-F",
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )
    synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)

    # Synthesize speech with specified emotional tone
    response = client.synthesize_speech(
        input=synthesis_input, voice=voice_params, audio_config=audio_config
    )
    return response.audio_content

# Sample text about climate issues
original_text = """
Climate change: Bangladesh is where it is at. Rohini Kamal shows the way.
Debates on climate change are often dominated by heated commentary from the West on its impending peril
calling it the biggest threat humanity has ever faced. But here in Bangladesh, climate change is not a threat – it is an ongoing reality.
"""

# Function to segment text into sentences
def segment_text(text):
    sentences = text.split('\n')
    return sentences

# Function to calculate Jaccard similarity
def jaccard_similarity(str1, str2):
    a = set(str1.split())
    b = set(str2.split())
    c = a.intersection(b)
    return float(len(c)) / (len(a) + len(b) - len(c))

# Function to calculate MOS (simplified placeholder)
def mos_score(text):
    return 4.5  # Placeholder score for demonstration

# Step 1: Segment the original text into sentences
segments = segment_text(original_text)

# Step 2: Define emotions and convert text to speech with different emotions and refined prosody settings
emotions = {
    "neutral": "<prosody pitch='0%' rate='1.0'>",
    "joyful": "<prosody pitch='+15%' rate='1.1'><break time='300ms'/>",
    "sad": "<prosody pitch='-15%' rate='0.85'><break time='500ms'/>",
    "angry": "<prosody pitch='+25%' rate='1.3'><break time='200ms'/>"
}

output_dir = "/content/output/"  # Specify the directory to save MP3 files

# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Initialize a list to store file paths
file_paths = []

# Process each emotion
for emotion, prosody in emotions.items():
    print(f"Emotion: {emotion.capitalize()}")
    print("=========================")
    ssml_parts = []
    for segment in segments:
        if segment.strip() != "":
            ssml_segment = f"<speak>{prosody}{segment.strip()}</prosody></speak>"
            audio_content = text_to_speech_ssml(ssml_segment)
            # Save the audio content to a file
            file_path = os.path.join(output_dir, f"{emotion}_speech.mp3")
            with open(file_path, "wb") as f:
                f.write(audio_content)
            file_paths.append(file_path)
            print(f"Segment: {segment.strip()}")

            # Display and play the audio in Colab
            display(Audio(audio_content))

print("Speech synthesis completed!")

# Provide download links for all generated MP3 files and calculate metrics
for file_path in file_paths:
    filename = os.path.basename(file_path)
    download_link = f"<a href='{file_path}' target='_blank'>Download {filename}</a>"
    display(HTML(download_link))

    # Calculate and display Jaccard similarity and MOS score
    with open(file_path, "rb") as audio_file:
        synthesized_text = original_text  # Placeholder: Replace with actual transcribed text if available
        jaccard = jaccard_similarity(original_text, synthesized_text)
        mos = mos_score(synthesized_text)
        print(f"Jaccard Similarity for {filename}: {jaccard}")
        print(f"MOS Score for {filename}: {mos}")